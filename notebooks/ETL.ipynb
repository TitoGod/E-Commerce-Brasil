{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ Leer los archivos CSV en Pandas\n",
    "\n",
    "Para cargar los archivos en Pandas, primero listamos los archivos disponibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos CSV encontrados: ['olist_customers_dataset.csv', 'olist_geolocation_dataset.csv', 'olist_orders_dataset.csv', 'olist_order_items_dataset.csv', 'olist_order_payments_dataset.csv', 'olist_order_reviews_dataset.csv', 'olist_products_dataset.csv', 'olist_sellers_dataset.csv', 'product_category_name_translation.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta donde tienes los CSV\n",
    "ruta_dataset = r\"C:\\Users\\Dario\\Desktop\\Proyectos Data\\Datasets\\Ecommerce_Brasil\"\n",
    "\n",
    "# Listar archivos disponibles\n",
    "archivos = os.listdir(ruta_dataset)\n",
    "print(\"Archivos CSV encontrados:\", archivos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos cada archivo en un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0           2017-10-18 00:00:00  \n",
      "1           2018-08-13 00:00:00  \n",
      "2           2018-09-04 00:00:00  \n",
      "3           2017-12-15 00:00:00  \n",
      "4           2018-02-26 00:00:00  \n",
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "# Cargar archivos en dataframes\n",
    "df_orders = pd.read_csv(os.path.join(ruta_dataset, \"olist_orders_dataset.csv\"))\n",
    "df_customers = pd.read_csv(os.path.join(ruta_dataset, \"olist_customers_dataset.csv\"))\n",
    "df_items = pd.read_csv(os.path.join(ruta_dataset, \"olist_order_items_dataset.csv\"))\n",
    "df_payments = pd.read_csv(os.path.join(ruta_dataset, \"olist_order_payments_dataset.csv\"))\n",
    "df_reviews = pd.read_csv(os.path.join(ruta_dataset, \"olist_order_reviews_dataset.csv\"))\n",
    "df_products = pd.read_csv(os.path.join(ruta_dataset, \"olist_products_dataset.csv\"))\n",
    "df_sellers = pd.read_csv(os.path.join(ruta_dataset, \"olist_sellers_dataset.csv\"))\n",
    "df_geolocation = pd.read_csv(os.path.join(ruta_dataset, \"olist_geolocation_dataset.csv\"))\n",
    "df_category = pd.read_csv(os.path.join(ruta_dataset, \"product_category_name_translation.csv\"))\n",
    "\n",
    "# Mostrar las primeras filas de cada dataframe\n",
    "print(df_orders.head())\n",
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣ Transformación de los Datos\n",
    "\n",
    "Ahora podemos hacer algunas transformaciones básicas para preparar los datos antes de cargarlos en SQL Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Fechas a Formato Datetime del dataframe df_orders\n",
    "\n",
    "df_orders['order_purchase_timestamp'] = pd.to_datetime(df_orders['order_purchase_timestamp'])\n",
    "df_orders['order_approved_at'] = pd.to_datetime(df_orders['order_approved_at'])\n",
    "df_orders['order_delivered_carrier_date'] = pd.to_datetime(df_orders['order_delivered_carrier_date'])\n",
    "df_orders['order_delivered_customer_date'] = pd.to_datetime(df_orders['order_delivered_customer_date'])\n",
    "df_orders['order_estimated_delivery_date'] = pd.to_datetime(df_orders['order_estimated_delivery_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                            0\n",
       "customer_id                         0\n",
       "order_status                        0\n",
       "order_purchase_timestamp            0\n",
       "order_approved_at                 160\n",
       "order_delivered_carrier_date     1783\n",
       "order_delivered_customer_date    2965\n",
       "order_estimated_delivery_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna\n",
    "\n",
    "df_orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0.00\n",
       "customer_id                      0.00\n",
       "order_status                     0.00\n",
       "order_purchase_timestamp         0.00\n",
       "order_approved_at                0.16\n",
       "order_delivered_carrier_date     1.79\n",
       "order_delivered_customer_date    2.98\n",
       "order_estimated_delivery_date    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porcentaje de valores nulos por columna\n",
    "\n",
    "(df_orders.isnull().mean() * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0\n",
       "customer_id                      0\n",
       "order_status                     0\n",
       "order_purchase_timestamp         0\n",
       "order_approved_at                0\n",
       "order_delivered_carrier_date     0\n",
       "order_delivered_customer_date    0\n",
       "order_estimated_delivery_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar filas con valores nulos en el dataframe de orders\n",
    "# Esto puede ser útil para evitar errores en análisis posteriores\n",
    "# Como son pocos los datos nulos, se pueden eliminar\n",
    "\n",
    "df_orders_clean = df_orders.dropna()\n",
    "df_orders_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de orders\n",
    "df_orders_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "order_purchase_timestamp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_approved_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_delivered_carrier_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_delivered_customer_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_estimated_delivery_date",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "deb829e0-b11a-48b7-8a29-6f85c4580596",
       "rows": [
        [
         "count",
         "96461",
         "96461",
         "96461",
         "96461",
         "96461"
        ],
        [
         "mean",
         "2018-01-01 23:53:26.642249216",
         "2018-01-02 10:10:06.480142336",
         "2018-01-05 05:21:04.508827392",
         "2018-01-14 13:17:13.228102400",
         "2018-01-25 17:33:14.236012544"
        ],
        [
         "min",
         "2016-09-15 12:16:38",
         "2016-09-15 12:16:38",
         "2016-10-08 10:34:01",
         "2016-10-11 13:46:32",
         "2016-10-04 00:00:00"
        ],
        [
         "25%",
         "2017-09-14 09:28:28",
         "2017-09-14 14:30:14",
         "2017-09-18 16:52:19",
         "2017-09-25 22:31:59",
         "2017-10-05 00:00:00"
        ],
        [
         "50%",
         "2018-01-20 19:59:42",
         "2018-01-22 13:49:00",
         "2018-01-24 16:19:03",
         "2018-02-02 19:50:56",
         "2018-02-16 00:00:00"
        ],
        [
         "75%",
         "2018-05-05 18:33:24",
         "2018-05-06 10:30:49",
         "2018-05-08 14:33:00",
         "2018-05-15 23:08:54",
         "2018-05-28 00:00:00"
        ],
        [
         "max",
         "2018-08-29 15:00:37",
         "2018-08-29 15:10:26",
         "2018-09-11 19:48:28",
         "2018-10-17 13:22:46",
         "2018-10-25 00:00:00"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018-01-01 23:53:26.642249216</td>\n",
       "      <td>2018-01-02 10:10:06.480142336</td>\n",
       "      <td>2018-01-05 05:21:04.508827392</td>\n",
       "      <td>2018-01-14 13:17:13.228102400</td>\n",
       "      <td>2018-01-25 17:33:14.236012544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016-09-15 12:16:38</td>\n",
       "      <td>2016-09-15 12:16:38</td>\n",
       "      <td>2016-10-08 10:34:01</td>\n",
       "      <td>2016-10-11 13:46:32</td>\n",
       "      <td>2016-10-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017-09-14 09:28:28</td>\n",
       "      <td>2017-09-14 14:30:14</td>\n",
       "      <td>2017-09-18 16:52:19</td>\n",
       "      <td>2017-09-25 22:31:59</td>\n",
       "      <td>2017-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018-01-20 19:59:42</td>\n",
       "      <td>2018-01-22 13:49:00</td>\n",
       "      <td>2018-01-24 16:19:03</td>\n",
       "      <td>2018-02-02 19:50:56</td>\n",
       "      <td>2018-02-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018-05-05 18:33:24</td>\n",
       "      <td>2018-05-06 10:30:49</td>\n",
       "      <td>2018-05-08 14:33:00</td>\n",
       "      <td>2018-05-15 23:08:54</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018-08-29 15:00:37</td>\n",
       "      <td>2018-08-29 15:10:26</td>\n",
       "      <td>2018-09-11 19:48:28</td>\n",
       "      <td>2018-10-17 13:22:46</td>\n",
       "      <td>2018-10-25 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_purchase_timestamp              order_approved_at  \\\n",
       "count                          96461                          96461   \n",
       "mean   2018-01-01 23:53:26.642249216  2018-01-02 10:10:06.480142336   \n",
       "min              2016-09-15 12:16:38            2016-09-15 12:16:38   \n",
       "25%              2017-09-14 09:28:28            2017-09-14 14:30:14   \n",
       "50%              2018-01-20 19:59:42            2018-01-22 13:49:00   \n",
       "75%              2018-05-05 18:33:24            2018-05-06 10:30:49   \n",
       "max              2018-08-29 15:00:37            2018-08-29 15:10:26   \n",
       "\n",
       "        order_delivered_carrier_date  order_delivered_customer_date  \\\n",
       "count                          96461                          96461   \n",
       "mean   2018-01-05 05:21:04.508827392  2018-01-14 13:17:13.228102400   \n",
       "min              2016-10-08 10:34:01            2016-10-11 13:46:32   \n",
       "25%              2017-09-18 16:52:19            2017-09-25 22:31:59   \n",
       "50%              2018-01-24 16:19:03            2018-02-02 19:50:56   \n",
       "75%              2018-05-08 14:33:00            2018-05-15 23:08:54   \n",
       "max              2018-09-11 19:48:28            2018-10-17 13:22:46   \n",
       "\n",
       "       order_estimated_delivery_date  \n",
       "count                          96461  \n",
       "mean   2018-01-25 17:33:14.236012544  \n",
       "min              2016-10-04 00:00:00  \n",
       "25%              2017-10-05 00:00:00  \n",
       "50%              2018-02-16 00:00:00  \n",
       "75%              2018-05-28 00:00:00  \n",
       "max              2018-10-25 00:00:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores anómalos en el dataframe de orders\n",
    "df_orders_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                 0\n",
       "customer_unique_id          0\n",
       "customer_zip_code_prefix    0\n",
       "customer_city               0\n",
       "customer_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de customers\n",
    "df_customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de customers\n",
    "df_customers.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                 0\n",
       "customer_unique_id          0\n",
       "customer_zip_code_prefix    0\n",
       "customer_city               0\n",
       "customer_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers_clean = df_customers.dropna()\n",
    "df_customers_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date   price  freight_value  \n",
      "0  2017-09-19 09:45:35   58.90          13.29  \n",
      "1  2017-05-03 11:05:13  239.90          19.93  \n",
      "2  2018-01-18 14:48:30  199.00          17.87  \n",
      "3  2018-08-15 10:10:18   12.99          12.79  \n",
      "4  2017-02-13 13:57:51  199.90          18.14  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del\n",
    "print(df_items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Fechas a Formato Datetime del dataframe df_items\n",
    "df_items['shipping_limit_date'] = pd.to_datetime(df_items['shipping_limit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id               0\n",
       "order_item_id          0\n",
       "product_id             0\n",
       "seller_id              0\n",
       "shipping_limit_date    0\n",
       "price                  0\n",
       "freight_value          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de items\n",
    "df_items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de items\n",
    "df_items.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id               0\n",
       "order_item_id          0\n",
       "product_id             0\n",
       "seller_id              0\n",
       "shipping_limit_date    0\n",
       "price                  0\n",
       "freight_value          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar filas con valores nulos en el dataframe de items\n",
    "df_items_clean = df_items.dropna()\n",
    "df_items_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id  payment_sequential payment_type  \\\n",
      "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
      "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
      "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
      "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
      "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
      "\n",
      "   payment_installments  payment_value  \n",
      "0                     8          99.33  \n",
      "1                     1          24.39  \n",
      "2                     1          65.71  \n",
      "3                     8         107.78  \n",
      "4                     2         128.45  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "order_id                0\n",
       "payment_sequential      0\n",
       "payment_type            0\n",
       "payment_installments    0\n",
       "payment_value           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de payments\n",
    "print(df_payments.head())\n",
    "\n",
    "# Verificar valores nulos por columna en el dataframe de payments\n",
    "df_payments.isnull().sum()\n",
    "\n",
    "# Verificar duplicados en el dataframe de payments\n",
    "df_payments.duplicated().sum()\n",
    "\n",
    "# Eliminar filas con valores nulos en el dataframe de payments\n",
    "df_payments_clean = df_payments.dropna()\n",
    "df_payments_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          review_id                          order_id  \\\n",
      "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
      "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
      "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
      "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
      "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
      "\n",
      "   review_score review_comment_title  \\\n",
      "0             4                  NaN   \n",
      "1             5                  NaN   \n",
      "2             5                  NaN   \n",
      "3             5                  NaN   \n",
      "4             5                  NaN   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0                                                NaN  2018-01-18 00:00:00   \n",
      "1                                                NaN  2018-03-10 00:00:00   \n",
      "2                                                NaN  2018-02-17 00:00:00   \n",
      "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
      "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
      "\n",
      "  review_answer_timestamp  \n",
      "0     2018-01-18 21:46:59  \n",
      "1     2018-03-11 03:05:13  \n",
      "2     2018-02-18 14:36:24  \n",
      "3     2017-04-21 22:02:06  \n",
      "4     2018-03-02 10:26:53  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de reviews\n",
    "print(df_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Fechas a Formato Datetime del dataframe df_reviews\n",
    "df_reviews['review_creation_date'] = pd.to_datetime(df_reviews['review_creation_date'])\n",
    "df_reviews['review_answer_timestamp'] = pd.to_datetime(df_reviews['review_answer_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar columnas innecesarias en el dataframe de reviews\n",
    "df_reviews_clean = df_reviews.drop(columns=['review_comment_title', 'review_comment_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                  0\n",
       "order_id                   0\n",
       "review_score               0\n",
       "review_creation_date       0\n",
       "review_answer_timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de reviews\n",
    "df_reviews_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de reviews\n",
    "df_reviews_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          seller_id  seller_zip_code_prefix  \\\n",
      "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
      "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
      "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
      "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
      "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
      "\n",
      "         seller_city seller_state  \n",
      "0           campinas           SP  \n",
      "1         mogi guacu           SP  \n",
      "2     rio de janeiro           RJ  \n",
      "3          sao paulo           SP  \n",
      "4  braganca paulista           SP  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de sellers\n",
    "print(df_sellers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seller_id                 0\n",
       "seller_zip_code_prefix    0\n",
       "seller_city               0\n",
       "seller_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de sellers\n",
    "df_sellers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seller_id                 0\n",
       "seller_zip_code_prefix    0\n",
       "seller_city               0\n",
       "seller_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de sellers\n",
    "df_sellers.duplicated().sum()\n",
    "df_sellers_clean = df_sellers.dropna()\n",
    "df_sellers_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
      "0                         1037       -23.545621       -46.639292   \n",
      "1                         1046       -23.546081       -46.644820   \n",
      "2                         1046       -23.546129       -46.642951   \n",
      "3                         1041       -23.544392       -46.639499   \n",
      "4                         1035       -23.541578       -46.641607   \n",
      "\n",
      "  geolocation_city geolocation_state  \n",
      "0        sao paulo                SP  \n",
      "1        sao paulo                SP  \n",
      "2        sao paulo                SP  \n",
      "3        sao paulo                SP  \n",
      "4        sao paulo                SP  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de geolocation\n",
    "print(df_geolocation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geolocation_zip_code_prefix    0\n",
       "geolocation_lat                0\n",
       "geolocation_lng                0\n",
       "geolocation_city               0\n",
       "geolocation_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de geolocation\n",
    "df_geolocation.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geolocation_zip_code_prefix    0\n",
       "geolocation_lat                0\n",
       "geolocation_lng                0\n",
       "geolocation_city               0\n",
       "geolocation_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de geolocation\n",
    "df_geolocation.duplicated().sum()\n",
    "df_geolocation_clean = df_geolocation.dropna()\n",
    "df_geolocation_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_products y df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         product_id  product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
      "\n",
      "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "0                 40.0                       287.0                 1.0   \n",
      "1                 44.0                       276.0                 1.0   \n",
      "2                 46.0                       250.0                 1.0   \n",
      "3                 27.0                       261.0                 1.0   \n",
      "4                 37.0                       402.0                 4.0   \n",
      "\n",
      "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
      "0             225.0               16.0               10.0              14.0  \n",
      "1            1000.0               30.0               18.0              20.0  \n",
      "2             154.0               18.0                9.0              15.0  \n",
      "3             371.0               26.0                4.0              26.0  \n",
      "4             625.0               20.0               17.0              13.0  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de products\n",
    "print(df_products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                      0\n",
       "product_category_name         610\n",
       "product_name_lenght           610\n",
       "product_description_lenght    610\n",
       "product_photos_qty            610\n",
       "product_weight_g                2\n",
       "product_length_cm               2\n",
       "product_height_cm               2\n",
       "product_width_cm                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar valores nulos por columna en el dataframe de products\n",
    "df_products.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                    0\n",
       "product_category_name         0\n",
       "product_name_lenght           0\n",
       "product_description_lenght    0\n",
       "product_photos_qty            0\n",
       "product_weight_g              0\n",
       "product_length_cm             0\n",
       "product_height_cm             0\n",
       "product_width_cm              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Borrar los datos nulos en el dataframe de products\n",
    "df_products = df_products.dropna()\n",
    "df_products.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar los dataframes de products y category\n",
    "df_products = pd.merge(df_products, df_category, how='left', left_on='product_category_name', right_on='product_category_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar columnas innecesarias en el dataframe de products\n",
    "df_products_clean = df_products.drop(columns=['product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
