{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ Leer los archivos CSV en Pandas\n",
    "\n",
    "Para cargar los archivos en Pandas, primero listamos los archivos disponibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos CSV encontrados: ['olist_customers_dataset.csv', 'olist_geolocation_dataset.csv', 'olist_orders_dataset.csv', 'olist_order_items_dataset.csv', 'olist_order_payments_dataset.csv', 'olist_order_reviews_dataset.csv', 'olist_products_dataset.csv', 'olist_sellers_dataset.csv', 'product_category_name_translation.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta donde tienes los CSV\n",
    "ruta_dataset = r\"C:\\Users\\Dario\\Desktop\\Proyectos Data\\Datasets\\Ecommerce_Brasil\"\n",
    "\n",
    "# Listar archivos disponibles\n",
    "archivos = os.listdir(ruta_dataset)\n",
    "print(\"Archivos CSV encontrados:\", archivos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos cada archivo en un DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id                       customer_id  \\\n",
      "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
      "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
      "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
      "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
      "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
      "\n",
      "  order_status order_purchase_timestamp    order_approved_at  \\\n",
      "0    delivered      2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
      "1    delivered      2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
      "2    delivered      2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
      "3    delivered      2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
      "4    delivered      2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
      "\n",
      "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
      "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
      "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
      "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
      "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
      "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
      "\n",
      "  order_estimated_delivery_date  \n",
      "0           2017-10-18 00:00:00  \n",
      "1           2018-08-13 00:00:00  \n",
      "2           2018-09-04 00:00:00  \n",
      "3           2017-12-15 00:00:00  \n",
      "4           2018-02-26 00:00:00  \n",
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "# Cargar archivos en dataframes\n",
    "df_orders = pd.read_csv(os.path.join(ruta_dataset, \"olist_orders_dataset.csv\"))\n",
    "df_customers = pd.read_csv(os.path.join(ruta_dataset, \"olist_customers_dataset.csv\"))\n",
    "df_items = pd.read_csv(os.path.join(ruta_dataset, \"olist_order_items_dataset.csv\"))\n",
    "df_payments = pd.read_csv(os.path.join(ruta_dataset, \"olist_order_payments_dataset.csv\"))\n",
    "df_reviews = pd.read_csv(os.path.join(ruta_dataset, \"olist_order_reviews_dataset.csv\"))\n",
    "df_products = pd.read_csv(os.path.join(ruta_dataset, \"olist_products_dataset.csv\"))\n",
    "df_sellers = pd.read_csv(os.path.join(ruta_dataset, \"olist_sellers_dataset.csv\"))\n",
    "df_geolocation = pd.read_csv(os.path.join(ruta_dataset, \"olist_geolocation_dataset.csv\"))\n",
    "df_category = pd.read_csv(os.path.join(ruta_dataset, \"product_category_name_translation.csv\"))\n",
    "\n",
    "# Mostrar las primeras filas de cada dataframe\n",
    "print(df_orders.head())\n",
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣ Transformación de los Datos\n",
    "\n",
    "Ahora podemos hacer algunas transformaciones básicas para preparar los datos antes de cargarlos en SQL Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Fechas a Formato Datetime del dataframe df_orders\n",
    "\n",
    "df_orders['order_purchase_timestamp'] = pd.to_datetime(df_orders['order_purchase_timestamp'])\n",
    "df_orders['order_approved_at'] = pd.to_datetime(df_orders['order_approved_at'])\n",
    "df_orders['order_delivered_carrier_date'] = pd.to_datetime(df_orders['order_delivered_carrier_date'])\n",
    "df_orders['order_delivered_customer_date'] = pd.to_datetime(df_orders['order_delivered_customer_date'])\n",
    "df_orders['order_estimated_delivery_date'] = pd.to_datetime(df_orders['order_estimated_delivery_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                            0\n",
       "customer_id                         0\n",
       "order_status                        0\n",
       "order_purchase_timestamp            0\n",
       "order_approved_at                 160\n",
       "order_delivered_carrier_date     1783\n",
       "order_delivered_customer_date    2965\n",
       "order_estimated_delivery_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna\n",
    "\n",
    "df_orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0.00\n",
       "customer_id                      0.00\n",
       "order_status                     0.00\n",
       "order_purchase_timestamp         0.00\n",
       "order_approved_at                0.16\n",
       "order_delivered_carrier_date     1.79\n",
       "order_delivered_customer_date    2.98\n",
       "order_estimated_delivery_date    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porcentaje de valores nulos por columna\n",
    "\n",
    "(df_orders.isnull().mean() * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0\n",
       "customer_id                      0\n",
       "order_status                     0\n",
       "order_purchase_timestamp         0\n",
       "order_approved_at                0\n",
       "order_delivered_carrier_date     0\n",
       "order_delivered_customer_date    0\n",
       "order_estimated_delivery_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar filas con valores nulos en el dataframe de orders\n",
    "# Esto puede ser útil para evitar errores en análisis posteriores\n",
    "# Como son pocos los datos nulos, se pueden eliminar\n",
    "\n",
    "df_orders_clean = df_orders.dropna()\n",
    "df_orders_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de orders\n",
    "df_orders_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "order_purchase_timestamp",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_approved_at",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_delivered_carrier_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_delivered_customer_date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "order_estimated_delivery_date",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "58fbf99b-37e5-445a-a855-437973871f09",
       "rows": [
        [
         "count",
         "96461",
         "96461",
         "96461",
         "96461",
         "96461"
        ],
        [
         "mean",
         "2018-01-01 23:53:26.642249216",
         "2018-01-02 10:10:06.480142336",
         "2018-01-05 05:21:04.508827392",
         "2018-01-14 13:17:13.228102400",
         "2018-01-25 17:33:14.236012544"
        ],
        [
         "min",
         "2016-09-15 12:16:38",
         "2016-09-15 12:16:38",
         "2016-10-08 10:34:01",
         "2016-10-11 13:46:32",
         "2016-10-04 00:00:00"
        ],
        [
         "25%",
         "2017-09-14 09:28:28",
         "2017-09-14 14:30:14",
         "2017-09-18 16:52:19",
         "2017-09-25 22:31:59",
         "2017-10-05 00:00:00"
        ],
        [
         "50%",
         "2018-01-20 19:59:42",
         "2018-01-22 13:49:00",
         "2018-01-24 16:19:03",
         "2018-02-02 19:50:56",
         "2018-02-16 00:00:00"
        ],
        [
         "75%",
         "2018-05-05 18:33:24",
         "2018-05-06 10:30:49",
         "2018-05-08 14:33:00",
         "2018-05-15 23:08:54",
         "2018-05-28 00:00:00"
        ],
        [
         "max",
         "2018-08-29 15:00:37",
         "2018-08-29 15:10:26",
         "2018-09-11 19:48:28",
         "2018-10-17 13:22:46",
         "2018-10-25 00:00:00"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 7
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_purchase_timestamp</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "      <td>96461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018-01-01 23:53:26.642249216</td>\n",
       "      <td>2018-01-02 10:10:06.480142336</td>\n",
       "      <td>2018-01-05 05:21:04.508827392</td>\n",
       "      <td>2018-01-14 13:17:13.228102400</td>\n",
       "      <td>2018-01-25 17:33:14.236012544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016-09-15 12:16:38</td>\n",
       "      <td>2016-09-15 12:16:38</td>\n",
       "      <td>2016-10-08 10:34:01</td>\n",
       "      <td>2016-10-11 13:46:32</td>\n",
       "      <td>2016-10-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017-09-14 09:28:28</td>\n",
       "      <td>2017-09-14 14:30:14</td>\n",
       "      <td>2017-09-18 16:52:19</td>\n",
       "      <td>2017-09-25 22:31:59</td>\n",
       "      <td>2017-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018-01-20 19:59:42</td>\n",
       "      <td>2018-01-22 13:49:00</td>\n",
       "      <td>2018-01-24 16:19:03</td>\n",
       "      <td>2018-02-02 19:50:56</td>\n",
       "      <td>2018-02-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018-05-05 18:33:24</td>\n",
       "      <td>2018-05-06 10:30:49</td>\n",
       "      <td>2018-05-08 14:33:00</td>\n",
       "      <td>2018-05-15 23:08:54</td>\n",
       "      <td>2018-05-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018-08-29 15:00:37</td>\n",
       "      <td>2018-08-29 15:10:26</td>\n",
       "      <td>2018-09-11 19:48:28</td>\n",
       "      <td>2018-10-17 13:22:46</td>\n",
       "      <td>2018-10-25 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_purchase_timestamp              order_approved_at  \\\n",
       "count                          96461                          96461   \n",
       "mean   2018-01-01 23:53:26.642249216  2018-01-02 10:10:06.480142336   \n",
       "min              2016-09-15 12:16:38            2016-09-15 12:16:38   \n",
       "25%              2017-09-14 09:28:28            2017-09-14 14:30:14   \n",
       "50%              2018-01-20 19:59:42            2018-01-22 13:49:00   \n",
       "75%              2018-05-05 18:33:24            2018-05-06 10:30:49   \n",
       "max              2018-08-29 15:00:37            2018-08-29 15:10:26   \n",
       "\n",
       "        order_delivered_carrier_date  order_delivered_customer_date  \\\n",
       "count                          96461                          96461   \n",
       "mean   2018-01-05 05:21:04.508827392  2018-01-14 13:17:13.228102400   \n",
       "min              2016-10-08 10:34:01            2016-10-11 13:46:32   \n",
       "25%              2017-09-18 16:52:19            2017-09-25 22:31:59   \n",
       "50%              2018-01-24 16:19:03            2018-02-02 19:50:56   \n",
       "75%              2018-05-08 14:33:00            2018-05-15 23:08:54   \n",
       "max              2018-09-11 19:48:28            2018-10-17 13:22:46   \n",
       "\n",
       "       order_estimated_delivery_date  \n",
       "count                          96461  \n",
       "mean   2018-01-25 17:33:14.236012544  \n",
       "min              2016-10-04 00:00:00  \n",
       "25%              2017-10-05 00:00:00  \n",
       "50%              2018-02-16 00:00:00  \n",
       "75%              2018-05-28 00:00:00  \n",
       "max              2018-10-25 00:00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores anómalos en el dataframe de orders\n",
    "df_orders_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "\n",
    "df_orders_clean.loc[:, 'order_id'] = df_orders_clean['order_id'].astype(str)\n",
    "df_orders_clean.loc[:, 'customer_id'] = df_orders_clean['customer_id'].astype(str)\n",
    "df_orders_clean.loc[:, 'order_status'] = df_orders_clean['order_status'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        customer_id                customer_unique_id  \\\n",
      "0  06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
      "1  18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
      "2  4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
      "3  b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
      "4  4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
      "\n",
      "   customer_zip_code_prefix          customer_city customer_state  \n",
      "0                     14409                 franca             SP  \n",
      "1                      9790  sao bernardo do campo             SP  \n",
      "2                      1151              sao paulo             SP  \n",
      "3                      8775        mogi das cruzes             SP  \n",
      "4                     13056               campinas             SP  \n"
     ]
    }
   ],
   "source": [
    "print(df_customers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                 0\n",
       "customer_unique_id          0\n",
       "customer_zip_code_prefix    0\n",
       "customer_city               0\n",
       "customer_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de customers\n",
    "df_customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de customers\n",
    "df_customers.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                 0\n",
       "customer_unique_id          0\n",
       "customer_zip_code_prefix    0\n",
       "customer_city               0\n",
       "customer_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers_clean = df_customers.dropna()\n",
    "df_customers_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "df_customers_clean.loc[:, 'customer_id'] = df_customers_clean['customer_id'].astype(str)\n",
    "df_customers_clean.loc[:, 'customer_unique_id'] = df_customers_clean['customer_unique_id'].astype(str)\n",
    "df_customers_clean.loc[:, 'customer_city'] = df_customers_clean['customer_city'].astype(str)\n",
    "df_customers_clean.loc[:, 'customer_state'] = df_customers_clean['customer_state'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date   price  freight_value  \n",
      "0  2017-09-19 09:45:35   58.90          13.29  \n",
      "1  2017-05-03 11:05:13  239.90          19.93  \n",
      "2  2018-01-18 14:48:30  199.00          17.87  \n",
      "3  2018-08-15 10:10:18   12.99          12.79  \n",
      "4  2017-02-13 13:57:51  199.90          18.14  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del\n",
    "print(df_items.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Fechas a Formato Datetime del dataframe df_items\n",
    "df_items['shipping_limit_date'] = pd.to_datetime(df_items['shipping_limit_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id               0\n",
       "order_item_id          0\n",
       "product_id             0\n",
       "seller_id              0\n",
       "shipping_limit_date    0\n",
       "price                  0\n",
       "freight_value          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de items\n",
    "df_items.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de items\n",
    "df_items.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id               0\n",
       "order_item_id          0\n",
       "product_id             0\n",
       "seller_id              0\n",
       "shipping_limit_date    0\n",
       "price                  0\n",
       "freight_value          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar filas con valores nulos en el dataframe de items\n",
    "df_items_clean = df_items.dropna()\n",
    "df_items_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "df_items_clean.loc[:, 'order_id'] = df_items_clean['order_id'].astype(str)\n",
    "df_items_clean.loc[:, 'product_id'] = df_items_clean['product_id'].astype(str)\n",
    "df_items_clean.loc[:, 'seller_id'] = df_items_clean['seller_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar ID unico para utilizar como primary key\n",
    "df_items_clean['item_id'] = df_items_clean.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           order_id  payment_sequential payment_type  \\\n",
      "0  b81ef226f3fe1789b1e8b2acac839d17                   1  credit_card   \n",
      "1  a9810da82917af2d9aefd1278f1dcfa0                   1  credit_card   \n",
      "2  25e8ea4e93396b6fa0d3dd708e76c1bd                   1  credit_card   \n",
      "3  ba78997921bbcdc1373bb41e913ab953                   1  credit_card   \n",
      "4  42fdf880ba16b47b59251dd489d4441a                   1  credit_card   \n",
      "\n",
      "   payment_installments  payment_value  \n",
      "0                     8          99.33  \n",
      "1                     1          24.39  \n",
      "2                     1          65.71  \n",
      "3                     8         107.78  \n",
      "4                     2         128.45  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "order_id                0\n",
       "payment_sequential      0\n",
       "payment_type            0\n",
       "payment_installments    0\n",
       "payment_value           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de payments\n",
    "print(df_payments.head())\n",
    "\n",
    "# Verificar valores nulos por columna en el dataframe de payments\n",
    "df_payments.isnull().sum()\n",
    "\n",
    "# Verificar duplicados en el dataframe de payments\n",
    "df_payments.duplicated().sum()\n",
    "\n",
    "# Eliminar filas con valores nulos en el dataframe de payments\n",
    "df_payments_clean = df_payments.dropna()\n",
    "df_payments_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "df_payments_clean.loc[:, 'order_id'] = df_payments_clean['order_id'].astype(str)\n",
    "df_payments_clean.loc[:, 'payment_type'] = df_payments_clean['payment_type'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar ID unico para utilizar como primary key\n",
    "df_payments_clean['payment_id'] = df_payments_clean.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          review_id                          order_id  \\\n",
      "0  7bc2406110b926393aa56f80a40eba40  73fc7af87114b39712e6da79b0a377eb   \n",
      "1  80e641a11e56f04c1ad469d5645fdfde  a548910a1c6147796b98fdf73dbeba33   \n",
      "2  228ce5500dc1d8e020d8d1322874b6f0  f9e4b658b201a9f2ecdecbb34bed034b   \n",
      "3  e64fb393e7b32834bb789ff8bb30750e  658677c97b385a9be170737859d3511b   \n",
      "4  f7c4243c7fe1938f181bec41a392bdeb  8e6bfb81e283fa7e4f11123a3fb894f1   \n",
      "\n",
      "   review_score review_comment_title  \\\n",
      "0             4                  NaN   \n",
      "1             5                  NaN   \n",
      "2             5                  NaN   \n",
      "3             5                  NaN   \n",
      "4             5                  NaN   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0                                                NaN  2018-01-18 00:00:00   \n",
      "1                                                NaN  2018-03-10 00:00:00   \n",
      "2                                                NaN  2018-02-17 00:00:00   \n",
      "3              Recebi bem antes do prazo estipulado.  2017-04-21 00:00:00   \n",
      "4  Parabéns lojas lannister adorei comprar pela I...  2018-03-01 00:00:00   \n",
      "\n",
      "  review_answer_timestamp  \n",
      "0     2018-01-18 21:46:59  \n",
      "1     2018-03-11 03:05:13  \n",
      "2     2018-02-18 14:36:24  \n",
      "3     2017-04-21 22:02:06  \n",
      "4     2018-03-02 10:26:53  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de reviews\n",
    "print(df_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir Fechas a Formato Datetime del dataframe df_reviews\n",
    "df_reviews['review_creation_date'] = pd.to_datetime(df_reviews['review_creation_date'])\n",
    "df_reviews['review_answer_timestamp'] = pd.to_datetime(df_reviews['review_answer_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar columnas innecesarias en el dataframe de reviews\n",
    "df_reviews_clean = df_reviews.drop(columns=['review_comment_title', 'review_comment_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id                  0\n",
       "order_id                   0\n",
       "review_score               0\n",
       "review_creation_date       0\n",
       "review_answer_timestamp    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de reviews\n",
    "df_reviews_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de reviews\n",
    "df_reviews_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "df_reviews_clean.loc[:, 'order_id'] = df_reviews_clean['order_id'].astype(str)\n",
    "df_reviews_clean.loc[:, 'review_id'] = df_reviews_clean['review_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar duplicados de la columna review_id\n",
    "df_reviews_clean = df_reviews_clean.drop_duplicates(subset=['review_id'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_sellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          seller_id  seller_zip_code_prefix  \\\n",
      "0  3442f8959a84dea7ee197c632cb2df15                   13023   \n",
      "1  d1b65fc7debc3361ea86b5f14c68d2e2                   13844   \n",
      "2  ce3ad9de960102d0677a81f5d0bb7b2d                   20031   \n",
      "3  c0f3eea2e14555b6faeea3dd58c1b1c3                    4195   \n",
      "4  51a04a8a6bdcb23deccc82b0b80742cf                   12914   \n",
      "\n",
      "         seller_city seller_state  \n",
      "0           campinas           SP  \n",
      "1         mogi guacu           SP  \n",
      "2     rio de janeiro           RJ  \n",
      "3          sao paulo           SP  \n",
      "4  braganca paulista           SP  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de sellers\n",
    "print(df_sellers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seller_id                 0\n",
       "seller_zip_code_prefix    0\n",
       "seller_city               0\n",
       "seller_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de sellers\n",
    "df_sellers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seller_id                 0\n",
       "seller_zip_code_prefix    0\n",
       "seller_city               0\n",
       "seller_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de sellers\n",
    "df_sellers.duplicated().sum()\n",
    "df_sellers_clean = df_sellers.dropna()\n",
    "df_sellers_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "df_sellers_clean.loc[:, 'seller_id'] = df_sellers_clean['seller_id'].astype(str)\n",
    "df_sellers_clean.loc[:, 'seller_city'] = df_sellers_clean['seller_city'].astype(str)\n",
    "df_sellers_clean.loc[:, 'seller_state'] = df_sellers_clean['seller_state'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   geolocation_zip_code_prefix  geolocation_lat  geolocation_lng  \\\n",
      "0                         1037       -23.545621       -46.639292   \n",
      "1                         1046       -23.546081       -46.644820   \n",
      "2                         1046       -23.546129       -46.642951   \n",
      "3                         1041       -23.544392       -46.639499   \n",
      "4                         1035       -23.541578       -46.641607   \n",
      "\n",
      "  geolocation_city geolocation_state  \n",
      "0        sao paulo                SP  \n",
      "1        sao paulo                SP  \n",
      "2        sao paulo                SP  \n",
      "3        sao paulo                SP  \n",
      "4        sao paulo                SP  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de geolocation\n",
    "print(df_geolocation.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geolocation_zip_code_prefix    0\n",
       "geolocation_lat                0\n",
       "geolocation_lng                0\n",
       "geolocation_city               0\n",
       "geolocation_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores nulos por columna en el dataframe de geolocation\n",
    "df_geolocation.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geolocation_zip_code_prefix    0\n",
       "geolocation_lat                0\n",
       "geolocation_lng                0\n",
       "geolocation_city               0\n",
       "geolocation_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de geolocation\n",
    "df_geolocation.duplicated().sum()\n",
    "df_geolocation_clean = df_geolocation.dropna()\n",
    "df_geolocation_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redondear las latitudes y longitudes\n",
    "# Redondear a 4 decimales\n",
    "df_geolocation_clean['geolocation_lat'] = df_geolocation_clean['geolocation_lat'].round(4)\n",
    "df_geolocation_clean['geolocation_lng'] = df_geolocation_clean['geolocation_lng'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "df_geolocation_clean.loc[:, 'geolocation_city'] = df_geolocation_clean['geolocation_city'].astype(str)\n",
    "df_geolocation_clean.loc[:, 'geolocation_state'] = df_geolocation_clean['geolocation_state'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(273916)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar duplicados en el dataframe de geolocation\n",
    "df_geolocation_clean.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar ID unico para utilizar como primary key\n",
    "df_geolocation_clean['geolocation_id'] = df_geolocation_clean.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_products y df_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         product_id  product_category_name  \\\n",
      "0  1e9e8ef04dbcff4541ed26657ea517e5             perfumaria   \n",
      "1  3aa071139cb16b67ca9e5dea641aaa2f                  artes   \n",
      "2  96bd76ec8810374ed1b65e291975717f          esporte_lazer   \n",
      "3  cef67bcfe19066a932b7673e239eb23d                  bebes   \n",
      "4  9dc1a7de274444849c219cff195d0b71  utilidades_domesticas   \n",
      "\n",
      "   product_name_lenght  product_description_lenght  product_photos_qty  \\\n",
      "0                 40.0                       287.0                 1.0   \n",
      "1                 44.0                       276.0                 1.0   \n",
      "2                 46.0                       250.0                 1.0   \n",
      "3                 27.0                       261.0                 1.0   \n",
      "4                 37.0                       402.0                 4.0   \n",
      "\n",
      "   product_weight_g  product_length_cm  product_height_cm  product_width_cm  \n",
      "0             225.0               16.0               10.0              14.0  \n",
      "1            1000.0               30.0               18.0              20.0  \n",
      "2             154.0               18.0                9.0              15.0  \n",
      "3             371.0               26.0                4.0              26.0  \n",
      "4             625.0               20.0               17.0              13.0  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas del dataframe de products\n",
    "print(df_products.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                      0\n",
       "product_category_name         610\n",
       "product_name_lenght           610\n",
       "product_description_lenght    610\n",
       "product_photos_qty            610\n",
       "product_weight_g                2\n",
       "product_length_cm               2\n",
       "product_height_cm               2\n",
       "product_width_cm                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificar valores nulos por columna en el dataframe de products\n",
    "df_products.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id                    0\n",
       "product_category_name         0\n",
       "product_name_lenght           0\n",
       "product_description_lenght    0\n",
       "product_photos_qty            0\n",
       "product_weight_g              0\n",
       "product_length_cm             0\n",
       "product_height_cm             0\n",
       "product_width_cm              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Borrar los datos nulos en el dataframe de products\n",
    "df_products = df_products.dropna()\n",
    "df_products.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar los dataframes de products y category\n",
    "df_products = pd.merge(df_products, df_category, how='left', left_on='product_category_name', right_on='product_category_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar columnas innecesarias en el dataframe de products\n",
    "df_products_clean = df_products.drop(columns=['product_category_name', 'product_name_lenght', 'product_description_lenght', 'product_photos_qty', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar las columnas de tipo object a string\n",
    "df_products_clean.loc[:, 'product_id'] = df_products_clean['product_id'].astype(str)\n",
    "df_products_clean.loc[:, 'product_category_name_english'] = df_products_clean['product_category_name_english'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de los datos a SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Parámetros de la conexión\n",
    "server = 'localhost\\\\SQLEXPRESS'  # Reemplaza con el nombre de tu servidor\n",
    "database = 'Ecommerce_Brasil'  # Reemplaza con el nombre de tu base de datos\n",
    "\n",
    "# Crear la cadena de conexión utilizando la autenticación de Windows\n",
    "connection_string = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "# Mandar los datos a la tabla ya creada en SQL Server\n",
    "df_geolocation_clean.to_sql('Geolocation', engine, if_exists='replace', index=False)\n",
    "df_customers_clean.to_sql('Customers', engine, if_exists='append', index=False)\n",
    "df_sellers_clean.to_sql('Sellers', engine, if_exists='append', index=False)\n",
    "df_orders_clean.to_sql('Orders', engine, if_exists='append', index=False)\n",
    "\n",
    "# Identificar los order_id que no existen en la tabla Orders\n",
    "with engine.connect() as conn:\n",
    "    # Obtener todos los order_id existentes en Orders\n",
    "    existing_orders = pd.read_sql(\"SELECT order_id FROM Orders\", conn)\n",
    "    \n",
    "    # Filtrar el DataFrame de Reviews\n",
    "    valid_reviews = df_reviews_clean[df_reviews_clean['order_id'].isin(existing_orders['order_id'])]\n",
    "    \n",
    "    # Insertar solo los registros válidos\n",
    "    valid_reviews.to_sql('Reviews', engine, if_exists='append', index=False)\n",
    "\n",
    "df_products_clean.to_sql('Product_Categories', engine, if_exists='append', index=False)\n",
    "# Faltan cargar items y payments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROBANDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Parámetros de la conexión\n",
    "server = 'localhost\\\\SQLEXPRESS'  # Reemplaza con el nombre de tu servidor\n",
    "database = 'Ecommerce_Brasil'  # Reemplaza con el nombre de tu base de datos\n",
    "\n",
    "# Crear la cadena de conexión utilizando la autenticación de Windows\n",
    "connection_string = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Identificar los order_id que no existen en la tabla Orders\n",
    "with engine.connect() as conn:\n",
    "    # Obtener todos los order_id existentes en Orders\n",
    "    existing_orders = pd.read_sql(\"SELECT order_id FROM Orders\", conn)\n",
    "    \n",
    "    # Filtrar el DataFrame de Reviews\n",
    "    valid_reviews = df_reviews_clean[df_reviews_clean['order_id'].isin(existing_orders['order_id'])]\n",
    "    \n",
    "    # Insertar solo los registros válidos\n",
    "    valid_reviews.to_sql('Reviews', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "(pyodbc.IntegrityError) ('23000', '[23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The INSERT statement conflicted with the FOREIGN KEY constraint \"FK_Payments_Orders\". The conflict occurred in database \"Ecommerce_Brasil\", table \"dbo.Orders\", column \\'order_id\\'. (547) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621)')\n[SQL: INSERT INTO [Payments] (order_id, payment_sequential, payment_type, payment_installments, payment_value, payment_id) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ... 6752 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n[parameters: ('b81ef226f3fe1789b1e8b2acac839d17', 1, 'credit_card', 8, 99.33, 1, 'a9810da82917af2d9aefd1278f1dcfa0', 1, 'credit_card', 1, 24.39, 2, '25e8ea4e93396b6fa0d3dd708e76c1bd', 1, 'credit_card', 1, 65.71, 3, 'ba78997921bbcdc1373bb41e913ab953', 1, 'credit_card', 8, 107.78, 4, '42fdf880ba16b47b59251dd489d4441a', 1, 'credit_card', 2, 128.45, 5, '298fcdf1f73eb413e4d26d01b25bc1cd', 1, 'credit_card', 2, 96.12, 6, '771ee386b001f06208a7419e4fc1bbd7', 1, 'credit_card', 1, 81.16, 7, '3d7239c394a212faae122962df514ac7', 1, 'credit_card', 3, 51.84, 8, '1f78449c87a54faf9e96e88ba1491fa9', 1 ... 1994 parameters truncated ... 256.37, 341, 'ce70855bb79f7086da0e4974f7324ac1', 1, 'credit_card', 1, 47.84, 342, '8f4be74e60d163c72a59ba577a642d70', 1, 'credit_card', 5, 125.87, 343, 'f26bbe1ba1d50321617831285d0fe62c', 1, 'credit_card', 1, 42.39, 344, '7246a71d326111872bfdfd34f495dc4f', 1, 'credit_card', 5, 117.53, 345, 'e65f1eeee1f52024ad1dcd03447f7482', 1, 'credit_card', 1, 43.28, 346, 'd2ebd7492d92dfb6a5737ba33a58f920', 1, 'credit_card', 4, 144.54, 347, '8e6df87600aae0285919b5529f7f0bfd', 1, 'boleto', 1, 126.48, 348, 'b45255a6696ebb8f53915a109a16458a', 1, 'credit_card', 4, 125.29, 349)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntegrityError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:2115\u001b[39m, in \u001b[36mConnection._exec_insertmany_context\u001b[39m\u001b[34m(self, dialect, context)\u001b[39m\n\u001b[32m   2114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2115\u001b[39m         \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2120\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIntegrityError\u001b[39m: ('23000', '[23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The INSERT statement conflicted with the FOREIGN KEY constraint \"FK_Payments_Orders\". The conflict occurred in database \"Ecommerce_Brasil\", table \"dbo.Orders\", column \\'order_id\\'. (547) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mIntegrityError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m engine = create_engine(connection_string)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Mandar los datos a la tabla ya creada en SQL Server\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mdf_payments_clean\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPayments\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:3087\u001b[39m, in \u001b[36mNDFrame.to_sql\u001b[39m\u001b[34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[39m\n\u001b[32m   2889\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2890\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   2891\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3083\u001b[39m \u001b[33;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   3085\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[32m-> \u001b[39m\u001b[32m3087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3088\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:842\u001b[39m, in \u001b[36mto_sql\u001b[39m\u001b[34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    838\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument should be either a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m     )\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema=schema, need_transaction=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:2018\u001b[39m, in \u001b[36mSQLDatabase.to_sql\u001b[39m\u001b[34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m   2006\u001b[39m sql_engine = get_engine(engine)\n\u001b[32m   2008\u001b[39m table = \u001b[38;5;28mself\u001b[39m.prep_table(\n\u001b[32m   2009\u001b[39m     frame=frame,\n\u001b[32m   2010\u001b[39m     name=name,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2015\u001b[39m     dtype=dtype,\n\u001b[32m   2016\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2018\u001b[39m total_inserted = \u001b[43msql_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert_records\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2025\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2027\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2028\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2030\u001b[39m \u001b[38;5;28mself\u001b[39m.check_case_sensitive(name=name, schema=schema)\n\u001b[32m   2031\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_inserted\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:1567\u001b[39m, in \u001b[36mSQLAlchemyEngine.insert_records\u001b[39m\u001b[34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[39m\n\u001b[32m   1565\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m re.search(msg, err_text):\n\u001b[32m   1566\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minf cannot be used with MySQL\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:1558\u001b[39m, in \u001b[36mSQLAlchemyEngine.insert_records\u001b[39m\u001b[34m(self, table, con, frame, name, index, schema, chunksize, method, **engine_kwargs)\u001b[39m\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m exc\n\u001b[32m   1557\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.StatementError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1560\u001b[39m     \u001b[38;5;66;03m# GH34431\u001b[39;00m\n\u001b[32m   1561\u001b[39m     \u001b[38;5;66;03m# https://stackoverflow.com/a/67358288/6067848\u001b[39;00m\n\u001b[32m   1562\u001b[39m     msg = \u001b[33mr\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33m(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m(1054, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown column \u001b[39m\u001b[33m'\u001b[39m\u001b[33minf(e0)?\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfield list\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m))(?#\u001b[39m\n\u001b[32m   1563\u001b[39m \u001b[33m    )|inf can not be used with MySQL\u001b[39m\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:1119\u001b[39m, in \u001b[36mSQLTable.insert\u001b[39m\u001b[34m(self, chunksize, method)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1118\u001b[39m chunk_iter = \u001b[38;5;28mzip\u001b[39m(*(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m num_inserted = \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\sql.py:1010\u001b[39m, in \u001b[36mSQLTable._execute_insert\u001b[39m\u001b[34m(self, conn, keys, data_iter)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    999\u001b[39m \u001b[33;03mExecute SQL statement inserting data\u001b[39;00m\n\u001b[32m   1000\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m \u001b[33;03m   Each item contains a list of values to be inserted\u001b[39;00m\n\u001b[32m   1008\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1009\u001b[39m data = [\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(keys, row)) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data_iter]\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m result = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result.rowcount\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:1416\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1414\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\sql\\elements.py:523\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    522\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:1638\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1626\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1627\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1628\u001b[39m )\n\u001b[32m   1630\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1631\u001b[39m     dialect=dialect,\n\u001b[32m   1632\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1636\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1637\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1638\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1651\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1652\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1653\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1657\u001b[39m         ret,\n\u001b[32m   1658\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:1841\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1838\u001b[39m context.pre_exec()\n\u001b[32m   1840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.execute_style \u001b[38;5;129;01mis\u001b[39;00m ExecuteStyle.INSERTMANYVALUES:\n\u001b[32m-> \u001b[39m\u001b[32m1841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_insertmany_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1842\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_single_context(\n\u001b[32m   1844\u001b[39m         dialect, context, statement, parameters\n\u001b[32m   1845\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:2123\u001b[39m, in \u001b[36mConnection._exec_insertmany_context\u001b[39m\u001b[34m(self, dialect, context)\u001b[39m\n\u001b[32m   2115\u001b[39m         dialect.do_execute(\n\u001b[32m   2116\u001b[39m             cursor,\n\u001b[32m   2117\u001b[39m             sub_stmt,\n\u001b[32m   2118\u001b[39m             sub_params,\n\u001b[32m   2119\u001b[39m             context,\n\u001b[32m   2120\u001b[39m         )\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2123\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2124\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2125\u001b[39m \u001b[43m        \u001b[49m\u001b[43msql_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_long_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2126\u001b[39m \u001b[43m        \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2127\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2128\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_sub_exec\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2130\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine_events:\n\u001b[32m   2133\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   2134\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2135\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2139\u001b[39m         context.executemany,\n\u001b[32m   2140\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:2352\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2350\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2351\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2354\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\base.py:2115\u001b[39m, in \u001b[36mConnection._exec_insertmany_context\u001b[39m\u001b[34m(self, dialect, context)\u001b[39m\n\u001b[32m   2113\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   2114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2115\u001b[39m         \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2117\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_stmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2118\u001b[39m \u001b[43m            \u001b[49m\u001b[43msub_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2119\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2120\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2122\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2123\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_dbapi_exception(\n\u001b[32m   2124\u001b[39m         e,\n\u001b[32m   2125\u001b[39m         sql_util._long_statement(sub_stmt),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2129\u001b[39m         is_sub_exec=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2130\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sqlalchemy\\engine\\default.py:945\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m945\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIntegrityError\u001b[39m: (pyodbc.IntegrityError) ('23000', '[23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The INSERT statement conflicted with the FOREIGN KEY constraint \"FK_Payments_Orders\". The conflict occurred in database \"Ecommerce_Brasil\", table \"dbo.Orders\", column \\'order_id\\'. (547) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621)')\n[SQL: INSERT INTO [Payments] (order_id, payment_sequential, payment_type, payment_installments, payment_value, payment_id) VALUES (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ... 6752 characters truncated ... , (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)]\n[parameters: ('b81ef226f3fe1789b1e8b2acac839d17', 1, 'credit_card', 8, 99.33, 1, 'a9810da82917af2d9aefd1278f1dcfa0', 1, 'credit_card', 1, 24.39, 2, '25e8ea4e93396b6fa0d3dd708e76c1bd', 1, 'credit_card', 1, 65.71, 3, 'ba78997921bbcdc1373bb41e913ab953', 1, 'credit_card', 8, 107.78, 4, '42fdf880ba16b47b59251dd489d4441a', 1, 'credit_card', 2, 128.45, 5, '298fcdf1f73eb413e4d26d01b25bc1cd', 1, 'credit_card', 2, 96.12, 6, '771ee386b001f06208a7419e4fc1bbd7', 1, 'credit_card', 1, 81.16, 7, '3d7239c394a212faae122962df514ac7', 1, 'credit_card', 3, 51.84, 8, '1f78449c87a54faf9e96e88ba1491fa9', 1 ... 1994 parameters truncated ... 256.37, 341, 'ce70855bb79f7086da0e4974f7324ac1', 1, 'credit_card', 1, 47.84, 342, '8f4be74e60d163c72a59ba577a642d70', 1, 'credit_card', 5, 125.87, 343, 'f26bbe1ba1d50321617831285d0fe62c', 1, 'credit_card', 1, 42.39, 344, '7246a71d326111872bfdfd34f495dc4f', 1, 'credit_card', 5, 117.53, 345, 'e65f1eeee1f52024ad1dcd03447f7482', 1, 'credit_card', 1, 43.28, 346, 'd2ebd7492d92dfb6a5737ba33a58f920', 1, 'credit_card', 4, 144.54, 347, '8e6df87600aae0285919b5529f7f0bfd', 1, 'boleto', 1, 126.48, 348, 'b45255a6696ebb8f53915a109a16458a', 1, 'credit_card', 4, 125.29, 349)]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Parámetros de la conexión\n",
    "server = 'localhost\\\\SQLEXPRESS'  # Reemplaza con el nombre de tu servidor\n",
    "database = 'Ecommerce_Brasil'  # Reemplaza con el nombre de tu base de datos\n",
    "\n",
    "# Crear la cadena de conexión utilizando la autenticación de Windows\n",
    "connection_string = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes'\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "# Mandar los datos a la tabla ya creada en SQL Server\n",
    "df_payments_clean.to_sql('Payments', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
